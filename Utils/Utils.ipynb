{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "l5SCT7d9h5_t"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5a2BHXVykHBb"
   },
   "outputs": [],
   "source": [
    "class FinalDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_path, y_path):\n",
    "      with open(X_path, 'rb') as x:\n",
    "        with open(y_path, 'rb') as y:\n",
    "          size = pkl.load(x)\n",
    "          self.X = pkl.load(x)\n",
    "          self.y = pkl.load(y)\n",
    "          for i in range(size - 1):\n",
    "            self.X = torch.cat([self.X, pkl.load(x)], dim= 0)\n",
    "            self.y = torch.cat([self.y, pkl.load(y)], dim= 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fG8rJRXpQWXY"
   },
   "outputs": [],
   "source": [
    "class FinalDatasetLite(Dataset):\n",
    "    def __init__(self, X_path, y_path):\n",
    "        self.x = open(X_path, 'rb')\n",
    "        self.y = open(y_path, 'rb')\n",
    "\n",
    "        self.size = pkl.load(self.x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return pkl.load(self.x).squeeze(1), pkl.load(self.y).squeeze(1)\n",
    "\n",
    "    def permuteBatch(X):\n",
    "        true_batch = 0\n",
    "        for i in range(X.shape[0]):\n",
    "          true_batch += X.shape[1]\n",
    "        return X.view(true_batch, X.shape[2], X.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yc5dWphykuLd"
   },
   "outputs": [],
   "source": [
    "def imshow(X, y):\n",
    "    y = y.detach()\n",
    "    lab_imgs = torch.cat([(X + 1) * 50., y * 110.], dim=1).permute(0, 2, 3, 1).cpu().numpy() # batch_size * h * w * c\n",
    "    rgb_imgs = []\n",
    "    for img in lab_imgs:\n",
    "        img_rgb = lab2rgb(img)\n",
    "        rgb_imgs.append(img_rgb)\n",
    "    for i in range(min(5, len(rgb_imgs))):\n",
    "        ax = plt.subplot(1, 5, i + 1)\n",
    "        ax.imshow(rgb_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SP7y5kBk1xw"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "  def __init__(self, in_channel, drop_prob, downSample = False):\n",
    "    super(ResidualBlock, self).__init__()\n",
    "    out_channel = in_channel\n",
    "    if(downSample):\n",
    "        out_channel = 2 * in_channel\n",
    "        self.downSampleConv = nn.Conv2d(in_channel, out_channel, kernel_size=1)\n",
    "        self.downSampleBatchNorm = nn.BatchNorm2d(out_channel)\n",
    "    self.downSample = downSample\n",
    "    self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, padding = 1)\n",
    "    self.batchNorm1 = nn.BatchNorm2d(out_channel)\n",
    "    self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, padding = 1)\n",
    "    self.batchNorm2 = nn.BatchNorm2d(out_channel)\n",
    "    self.drop = nn.Dropout2d(drop_prob)\n",
    "    self.act = nn.ReLU(True)\n",
    "    self._initialize_weights()\n",
    "\n",
    "  def forward(self, x):\n",
    "    residual = x\n",
    "    x = self.conv1(x)\n",
    "    x = self.batchNorm1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.batchNorm2(x)\n",
    "    x = self.drop(x)\n",
    "    if(self.downSample):\n",
    "        residual = self.downSampleConv(residual)\n",
    "        residual = self.downSampleBatchNorm(residual)\n",
    "    x += residual\n",
    "    return self.act(x)\n",
    "\n",
    "  def _initialize_weights(self):\n",
    "    nn.init.constant_(self.batchNorm2.weight, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5G3o31Zw8yN"
   },
   "outputs": [],
   "source": [
    "def residual_layer(block, layerSize, in_channel, drop_prob):\n",
    "    layers = []\n",
    "    layers.append(block(in_channel, drop_prob, True))                       # First layer requires downsample and set num of filters to twice from before\n",
    "    for i in range(layerSize-1):\n",
    "        layers.append(block(2*in_channel, drop_prob))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "    return self.act(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lM8aprBcJQo3"
   },
   "outputs": [],
   "source": [
    "def clearCache():\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFgx9oOBzH57"
   },
   "outputs": [],
   "source": [
    "def saveModel(model, filepath):\n",
    "  torch.save(model.state_dict(), filepath)\n",
    "  print('\\nSaved model to ' + filepath + '.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
